{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from __future__ import division\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "\n",
    "from tqdm import trange\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the excel sheet \n",
    "df = pd.read_excel('./BioCode for Machine Learning Updated.xlsx')\n",
    "\n",
    "# Read in the labels\n",
    "cls = df['Classification']\n",
    "\n",
    "# Read the DNA sequences, which are strings comprised of the letters ATCG\n",
    "seq = df['Aligned Sequence']\n",
    "\n",
    "species = df['NCBI_Genus_species']\n",
    "\n",
    "avgdist = df['avg_min_distance']\n",
    "windist = df['win_sp_distance']\n",
    "bdist = df['Distance_of_Branch']\n",
    "avgsim = df['avg_Similarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4459, 6)\n",
      "(1354, 6)\n",
      "(1354,)\n",
      "(1354,)\n",
      "(1354, 4)\n"
     ]
    }
   ],
   "source": [
    "feats = np.vstack([avgdist, windist, bdist, avgsim, cls, species]).T\n",
    "\n",
    "print(feats.shape)\n",
    "\n",
    "pd_feats = pd.DataFrame(feats)\n",
    "pd_feats = pd_feats.dropna()\n",
    "\n",
    "# print(pd_feats)\n",
    "\n",
    "feats = np.array(pd_feats)\n",
    "print(feats.shape)\n",
    "\n",
    "cls = feats[:, -2:-1]\n",
    "species = feats[:, -1:]\n",
    "feats = feats[:, :-2]\n",
    "\n",
    "# for i in range(len(feats)):\n",
    "#     print(feats[i])\n",
    "\n",
    "species = species.reshape(-1)\n",
    "cls = cls.reshape(-1)\n",
    "\n",
    "print(species.shape)\n",
    "print(cls.shape)\n",
    "print(feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DNA data to numpy array, and convert NaNs to Nones\n",
    "# seq = np.array(seq.fillna('None'))\n",
    "\n",
    "# Create a binary filter to eliminate invalid DNA sequences\n",
    "valid_idx = np.array([i for i in range(len(seq)) if seq[i] != 'None'])\n",
    "\n",
    "# Apply the filter\n",
    "valid_seq = seq # [valid_idx]\n",
    "cls_valid = cls # [valid_idx]\n",
    "cls_valid = np.array(cls_valid)\n",
    "species = species # [valid_idx]\n",
    "\n",
    "feats = feats # [valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4459 1354 4459\n"
     ]
    }
   ],
   "source": [
    "# Seperate string into individual characters\n",
    "seq_arrays = [np.array([i for i in s]) for s in valid_seq]\n",
    "\n",
    "mat_size = len(seq_arrays)\n",
    "\n",
    "print(len(valid_seq), len(cls_valid), mat_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1354 1354\n"
     ]
    }
   ],
   "source": [
    "valid_labels = ['Introduced', 'Invasive', 'Indigenous']\n",
    "labeled_cls = [label in valid_labels for label in cls_valid]\n",
    "#labeled_cls = (valid_labels[labeled_cls] == 'Indigenous').astype(int)\n",
    "\n",
    "print(len(labeled_cls), len(species))\n",
    "\n",
    "# Create a filter telling us which points are valid to use for supervised training\n",
    "labeled_cls = np.array(labeled_cls)\n",
    "cls_valid[labeled_cls]\n",
    "species_valid = species[labeled_cls]\n",
    "\n",
    "feats = feats[labeled_cls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the filter over our features and labels\n",
    "# supervised_X = approx[labeled_cls]\n",
    "# full_supervised_X = valid_mat[labeled_cls]\n",
    "supervised_y = cls_valid[labeled_cls]\n",
    "supervised_y = (supervised_y == 'Indigenous').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = set()\n",
    "species_filter = []\n",
    "for i in species_valid:\n",
    "    if i not in unique:\n",
    "        species_filter.append(True)\n",
    "        unique.add(i)\n",
    "    else:\n",
    "        species_filter.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised_X = supervised_X[species_filter]\n",
    "# full_supervised_X = full_supervised_X[species_filter]\n",
    "supervised_y = supervised_y[species_filter]\n",
    "feats = feats[species_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(231, 4)\n"
     ]
    }
   ],
   "source": [
    "print(feats.shape)\n",
    "test_train_ratio = 0.5\n",
    "feats_train, feats_test, y_train, y_test = train_test_split(feats, supervised_y, test_size=test_train_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115, 4) (116, 4)\n"
     ]
    }
   ],
   "source": [
    "print(feats_train.shape, feats_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16379310344827586\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.190333333 0.029 0.0953 97.27333333]\n",
      "[0.149986667 0.002066667 0.0654 99.81609524]\n",
      "[0.149986667 0.002066667 0.0654 99.81609524]\n",
      "[0.149986667 0.002066667 0.0654 99.81609524]\n",
      "[0.149986667 0.002066667 0.0654 99.81609524]\n",
      "[0.203375 0.007833333 0.0974 99.502]\n",
      "[0.203375 0.007833333 0.0974 99.502]\n",
      "[0.24075 0.0 0.1393 99.79]\n",
      "[0.106125 0.003 0.0492 99.7975]\n",
      "[0.191454545 0.005581818 0.0823 99.70818182]\n",
      "[0.191454545 0.005581818 0.0823 99.70818182]\n",
      "[0.192 0.016 0.0904 98.46]\n",
      "[0.1525 0.002607143 0.0729 99.96678571]\n",
      "[0.178666667 0.002 0.0885 99.85]\n",
      "[0.178666667 0.014666667 0.0724 98.58]\n",
      "[0.189375 0.006694444 0.0972 99.96027778]\n",
      "[0.18784375 0.021642857 0.0674 99.16142857]\n",
      "[0.18784375 0.021642857 0.0674 99.16142857]\n",
      "[0.18784375 0.021642857 0.0674 99.16142857]\n",
      "[0.18784375 0.021642857 0.0674 99.16142857]\n",
      "[0.18784375 0.001 0.0948 99.925]\n",
      "[0.2128 0.0304 0.0863 96.928]\n",
      "[0.11325 0.019 0.0682 98.36]\n",
      "[0.214333333 0.002 0.1118 99.84666667]\n",
      "[0.21 0.008 0.1003 99.24]\n",
      "[0.2262 0.015 0.1039 99.634]\n",
      "[0.196 0.004666667 0.0901 99.66]\n",
      "[0.166166667 0.0376 0.0598 96.488]\n",
      "[0.094875 0.003 0.0477 99.7]\n",
      "[0.0975 0.002 0.0517 99.85]\n",
      "[0.0975 0.029 0.0272 97.11]\n",
      "[0.0975 0.029 0.0272 97.11]\n",
      "[0.1195 0.004 0.0578 99.63]\n",
      "[0.1135 0.001688889 0.055 99.91288889]\n",
      "[0.1135 0.001688889 0.055 99.91288889]\n",
      "[0.074 0.002 0.0326 100.0]\n",
      "[0.066666667 0.000866667 0.0279 99.92266667]\n",
      "[0.083166667 0.006666667 0.0435 99.42333333]\n",
      "[0.069545455 0.009818182 0.0313 99.06854545]\n",
      "[0.206277778 0.000666667 0.1191 100.0]\n",
      "[0.1885 0.0 0.0909 100.0]\n",
      "[0.1923125 0.003785714 0.0951 99.87285714]\n",
      "[0.093666667 0.002866667 0.0367 99.866]\n",
      "[0.114333333 0.000933333 0.0589 100.0]\n",
      "[0.159142857 0.009758242 0.0761 99.03736264]\n",
      "[0.130506494 0.001345455 0.0693 99.94654545]\n",
      "[0.11452381 0.003190476 0.0518 99.72857143]\n",
      "[0.095045455 0.006813853 0.0388 99.66385281]\n",
      "[0.0504 0.0 0.0214 100.0]\n",
      "[0.0504 0.0052 0.0258 99.915]\n",
      "[0.064365079 0.008428571 0.0291 99.31285714]\n",
      "[0.078 0.001 0.034 100.0]\n",
      "[0.074 0.019 0.0309 98.13]\n",
      "[0.115 0.001 0.0614 100.0]\n",
      "[0.1263125 0.003714286 0.0609 99.72714286]\n",
      "[0.148433333 0.011257143 0.0757 99.31933333]\n",
      "[0.1455 0.002333333 0.0709 99.79733333]\n",
      "[0.1128 0.001965517 0.0486 99.91590805]\n",
      "[0.138884615 0.000717949 0.0777 99.94397436]\n",
      "[0.046181818 0.024090909 0.0015 97.57890909]\n",
      "[0.046181818 0.024090909 0.0015 97.57890909]\n",
      "[0.13075 0.006833333 0.0692 99.46166667]\n",
      "[0.108083333 0.000333333 0.0477 99.975]\n",
      "[0.0915 0.002 0.0341 99.85]\n",
      "[0.175921053 0.003596491 0.0929 99.92380117]\n",
      "[0.178458333 0.004666667 0.0899 99.47333333]\n",
      "[0.15925 0.001924242 0.0899 100.0]\n",
      "[0.179888889 0.006333333 0.0946 99.34]\n",
      "[0.136666667 0.012 0.0712 99.59333333]\n",
      "[0.396 0.0 0.2482 100.0]\n",
      "[0.1955 0.011 0.101 98.78]\n",
      "[0.1955 0.011 0.101 98.78]\n",
      "[0.196148148 0.036478632 0.0627 99.08094017]\n",
      "[0.132 0.013 0.073 100.0]\n",
      "[0.097857143 0.08647619 0.0364 99.80952381]\n",
      "[0.101 0.07025 0.0278 99.81642857]\n",
      "[0.101 0.07025 0.0278 99.81642857]\n",
      "[0.099 0.0108 0.0396 98.908]\n",
      "[0.252 0.002 0.1195 99.85]\n",
      "[0.2025 0.0 0.1194 100.0]\n",
      "[0.284666667 0.008 0.1626 100.0]\n",
      "[0.188 0.0 0.0928 100.0]\n",
      "[0.226333333 0.038333333 0.1019 100.0]\n",
      "[0.186 0.0 0.0953 100.0]\n",
      "[0.189722222 0.002 0.0855 99.85]\n",
      "[0.242694444 0.0102 0.1169 99.94666667]\n",
      "[0.242694444 0.004466667 0.1175 99.596]\n",
      "[0.154 0.003 0.072 99.7]\n",
      "[0.248 0.07947619 0.0431 96.82904762]\n",
      "[0.383777778 0.071 0.1217 97.04472222]\n",
      "[0.351833333 0.065933333 0.1271 96.582]\n",
      "[0.140166667 0.0048 0.0493 99.54266667]\n",
      "[0.140166667 0.0048 0.0493 99.54266667]\n",
      "[0.05 0.002 0.0093 99.85]\n",
      "[0.35625 0.0015 0.254 100.0]\n",
      "[0.187272727 0.005077922 0.1019 99.80861472]\n",
      "[0.187272727 0.0 0.0793 100.0]\n",
      "[0.21225 0.010166667 0.1044 99.505]\n",
      "[0.143 0.0 0.0603 100.0]\n",
      "[0.06152381 0.008742857 0.1111 99.98490476]\n",
      "[0.193142857 0.018615385 0.0626 98.80373626]\n",
      "[0.218142857 0.025952381 0.0856 99.83095238]\n",
      "[0.218142857 0.025952381 0.0856 99.83095238]\n",
      "[0.218142857 0.025952381 0.0856 99.83095238]\n",
      "[0.202666667 0.010666667 0.0955 99.68666667]\n",
      "[0.218481481 0.006166667 0.11 100.0]\n",
      "[0.232111111 0.009666667 0.1182 99.50333333]\n",
      "[0.232111111 0.009666667 0.1182 99.50333333]\n",
      "[0.112 0.0 0.0515 100.0]\n",
      "[0.0935 0.023333333 0.0326 97.78666667]\n",
      "[0.181 0.0 0.0713 100.0]\n",
      "[0.177388889 0.001333333 0.0838 100.0]\n",
      "[0.2063125 0.0 0.102 100.0]\n",
      "[0.114 0.0 0.0491 100.0]\n",
      "[0.22425 0.003464286 0.1183 96.61571429]\n",
      "[0.0565 0.003 0.0262 99.84]\n",
      "[0.197357143 0.012619048 0.0973 99.96761905]\n",
      "[0.13356125 0.005610887 0.0532 99.98711694]\n",
      "[0.13356125 0.01687 0.0643 99.73]\n",
      "[0.139664773 0.015337662 0.0825 99.12593074]\n",
      "[0.139664773 0.0124 0.0318 99.13383333]\n",
      "[0.1148 0.0092 0.041 99.089]\n",
      "[0.209 0.0051 0.1152 99.952]\n",
      "[0.217666667 0.006666667 0.1177 99.90666667]\n",
      "[0.17825 0.0015 0.0946 100.0]\n",
      "[0.220142857 0.003904762 0.1084 99.97714286]\n",
      "[0.044615385 0.005820513 0.0115 99.74705128]\n",
      "[0.157384615 0.007576923 0.0903 99.97538462]\n",
      "[0.074090909 0.025818182 0.0226 99.058]\n",
      "[0.074090909 0.025818182 0.0226 99.058]\n",
      "[0.074090909 0.025818182 0.0226 99.058]\n",
      "[0.074090909 0.025818182 0.0226 99.058]\n",
      "[0.074090909 0.025818182 0.0226 99.058]\n",
      "[0.1361875 0.0057 0.0532 99.97608333]\n",
      "[0.042833333 0.003784314 0.0177 99.97836601]\n",
      "[0.07703125 0.001392857 0.0283 99.88214286]\n",
      "[0.04121875 0.005392857 0.0147 99.76285714]\n",
      "[0.098 0.0 0.0501 100.0]\n",
      "[0.103 0.0 0.0544 100.0]\n",
      "[0.0795 0.002 0.0355 100.0]\n",
      "[0.07544 0.0076 0.0359 99.879]\n",
      "[0.044388889 0.003 0.0236 99.66]\n",
      "[0.067 0.0 0.0284 100.0]\n",
      "[0.068857143 0.006666667 0.0337 100.0]\n",
      "[0.029 0.005238095 0.0098 99.71857143]\n",
      "[0.029 0.005238095 0.0098 99.71857143]\n",
      "[0.029 0.005238095 0.0098 99.71857143]\n",
      "[0.0838 0.003489474 0.0382 99.98736842]\n",
      "[0.094416667 0.001787879 0.0487 99.92909091]\n",
      "[0.092 0.0 0.0509 100.0]\n",
      "[0.111285714 0.012666667 0.0581 99.95]\n",
      "[0.046357143 0.011 0.0246 99.7]\n",
      "[0.046357143 0.011 0.0246 99.7]\n",
      "[0.123253968 0.005833333 0.0438 99.75472222]\n",
      "[0.123253968 0.005833333 0.0438 99.75472222]\n",
      "[0.123253968 0.005833333 0.0438 99.75472222]\n",
      "[0.034552632 0.00374269 0.0185 99.9902924]\n",
      "[0.133 0.008742424 0.0635 99.74409091]\n",
      "[0.148 0.0 0.0793 100.0]\n",
      "[0.068493056 0.0035 0.0355 99.66]\n",
      "[0.10125 0.003933333 0.0571 99.85733333]\n",
      "[0.099333333 0.005333333 0.0519 99.42]\n",
      "[0.0458 0.0078 0.0102 99.422]\n",
      "[0.047375 0.009666667 0.0173 99.81333333]\n",
      "[0.079025 0.001 0.0407 100.0]\n",
      "[0.078714286 0.006190476 0.0339 99.90571429]\n",
      "[0.0235 0.001 0.0143 100.0]\n",
      "[0.08 0.0025 0.0402 99.77333333]\n",
      "[0.109775 0.0069 0.0508 99.574]\n",
      "[0.151333333 0.006 0.0703 100.0]\n",
      "[0.068 0.0 0.0324 100.0]\n",
      "[0.066 0.006643275 0.0275 99.73719298]\n",
      "[0.066 0.006643275 0.0275 99.73719298]\n",
      "[0.084333333 0.001666667 0.0357 100.0]\n",
      "[0.152444444 0.0045 0.0849 99.91416667]\n",
      "[0.14025 0.008333333 0.0619 99.79]\n",
      "[0.096666667 0.020666667 0.0382 98.63]\n",
      "[0.05725 0.001333333 0.0315 100.0]\n",
      "[0.0723 0.004733333 0.0234 100.0]\n",
      "[0.07544 0.0112 0.0245 99.214]\n",
      "[0.07703125 0.010333333 0.0399 100.0]\n",
      "[0.1475 0.001 0.0893 100.0]\n",
      "[0.04121875 0.007666667 0.0167 100.0]\n",
      "[0.031 0.0 0.0151 100.0]\n",
      "[0.0885 0.004257576 0.0421 100.0]\n",
      "[0.09625 0.0012 0.0364 99.955]\n",
      "[0.0625 0.003 0.0305 100.0]\n",
      "[0.1326 0.0085 0.0688 100.0]\n",
      "[0.08425 0.0025 0.0416 100.0]\n",
      "[0.053714286 0.0 0.031 100.0]\n",
      "[0.128 0.0 0.0576 100.0]\n",
      "[0.065 0.0 0.0339 100.0]\n",
      "[0.139666667 0.001333333 0.0707 99.9]\n",
      "[0.1055 0.004866667 0.0643 99.788]\n",
      "[0.104388889 0.0 0.0558 100.0]\n",
      "[0.156222222 0.009378917 0.0787 99.89894587]\n",
      "[0.156222222 0.009378917 0.0787 99.89894587]\n",
      "[0.038277778 0.005666667 0.0116 99.48]\n",
      "[0.115444444 0.002805556 0.0601 99.7475]\n",
      "[0.115444444 0.002805556 0.0601 99.7475]\n",
      "[0.092692308 0.00974359 0.047 99.91551282]\n",
      "[0.095429688 0.007975 0.0439 99.93566667]\n",
      "[0.115307692 0.007076923 0.0374 99.70730769]\n",
      "[0.115307692 0.007076923 0.0374 99.70730769]\n",
      "[0.105166667 0.008866667 0.0517 99.944]\n",
      "[0.041066667 0.0096 0.0168 100.0]\n",
      "[0.169 0.012 0.0857 100.0]\n",
      "[0.087 0.0 0.0441 100.0]\n",
      "[0.10825 0.002636364 0.0487 99.78409091]\n",
      "[0.033111111 0.002 0.0072 99.64666667]\n",
      "[0.05625 0.009 0.024 100.0]\n",
      "[0.09625 0.007333333 0.0533 100.0]\n",
      "[0.0283 0.007666667 0.0128 100.0]\n",
      "[0.064716049 0.004810458 0.0286 99.98764706]\n",
      "[0.082111111 0.005066176 0.0417 100.0]\n",
      "[0.11 0.0 0.0449 100.0]\n",
      "[0.1105 0.00775 0.0561 99.9375]\n",
      "[0.033111111 0.007916667 0.0183 100.0]\n",
      "[0.034552632 0.009052381 0.0063 99.38626984]\n",
      "[0.153 0.014178571 0.0619 99.96785714]\n",
      "[0.130518519 0.003533333 0.0665 100.0]\n",
      "[0.112 0.0 0.0681 100.0]\n",
      "[0.086821429 0.00075 0.0361 100.0]\n",
      "[0.103222222 0.005638889 0.0517 99.42972222]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.103222222 0.005638889 0.0517 99.42972222]\n",
      "[0.17775 0.003181818 0.0895 99.71757576]\n",
      "[0.1183 0.008155556 0.0366 99.75133333]\n",
      "[0.17775 0.0 0.083 100.0]\n",
      "[0.382 0.0067 0.251 99.507]\n",
      "[0.29325 0.015166667 0.1295 100.0]\n",
      "[0.300125 0.003 0.1585 100.0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(feats)):\n",
    "    print(feats[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediciton accuracy: 0.8362068965517241\n",
      "Weights: [[-0.72382385  0.06467485 -0.3861888  -0.94038613]]\n"
     ]
    }
   ],
   "source": [
    "clf = sk.linear_model.LogisticRegression() # class_weight = {0:0.15, 1:0.85})\n",
    "clf.fit(feats_train, y_train)\n",
    "prediction = (clf.predict(feats_test) > 0.5)*1 #Threshold\n",
    "#Prediction accuracy\n",
    "print('Prediciton accuracy:', np.mean((prediction == np.array(y_test))*1))\n",
    "#Coefficients used by the classifier\n",
    "print(\"Weights:\", clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediciton accuracy: 0.8362068965517241\n"
     ]
    }
   ],
   "source": [
    "cls = SVC() # class_weight = {0:0.15, 1:0.85})\n",
    "cls.fit(feats_train, y_train)\n",
    "prediction = (cls.predict(feats_test) > 0.5)*1 #Threshold\n",
    "#Prediction accuracy\n",
    "print('Prediciton accuracy:', np.mean((prediction == np.array(y_test))*1))\n",
    "#Coefficients used by the classifier\n",
    "# print(\"Weights:\", clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
